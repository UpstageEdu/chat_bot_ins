# inference.py
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "0"
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel
from utils.prompts import ALPACA_PROMPT_TEMPLATE, ALPACA_PROMPT_WITHOUT_INPUT_TEMPLATE

def run_inference(model, tokenizer, instruction):
    """
    ì£¼ì–´ì§„ instructionê³¼ inputìœ¼ë¡œ ì¶”ë¡ ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    # 1. í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = ALPACA_PROMPT_WITHOUT_INPUT_TEMPLATE.format(instruction=instruction)

    # 2. í† í¬ë‚˜ì´ì§•
    inputs = tokenizer(prompt, return_tensors="pt").to("cuda")

    # 3. ëª¨ë¸ ì¶”ë¡ 
    print("ì¶”ë¡  ì¤‘...")
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=150,
            eos_token_id=tokenizer.eos_token_id,
            pad_token_id=tokenizer.pad_token_id,
            do_sample=True,
            temperature=0.7,
            top_p=0.9
        )
    
    # 4. ê²°ê³¼ ë””ì½”ë”© ë° ì¶œë ¥
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    
    
    for tag in ["### ì‘ë‹µ:", "### Response:"]:
        if tag in response:
            return response.split(tag, 1)[1].strip()
    # 
    return response[len(prompt):].strip()


def main():
    # 1. í•™ìŠµ ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
    model_path = "checkpoints/gpt2-lora/checkpoint-100"
    print(f"'{model_path}'ì—ì„œ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤...")
    
    model = AutoModelForCausalLM.from_pretrained('gpt2', device_map="auto")
    tokenizer = AutoTokenizer.from_pretrained('gpt2')
    model = PeftModel.from_pretrained(model, model_path)
    
    print("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")

    # 2. ì¶”ë¡ í•  ìƒ˜í”Œ ë°ì´í„°
    sample_instruction = "ì‹¤ì† ë³´í—˜ê³¼ ì¢…í•© ë³´í—˜ì˜ ê°€ì¥ í° ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?"
    
    # 3. ì¶”ë¡  ì‹¤í–‰
    generated_answer = run_inference(model, tokenizer, sample_instruction)
    
    # 4. ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*50)
    print(f"ğŸ“œ ì§ˆë¬¸: {sample_instruction}")
    print(f"ğŸ¤– ìƒì„±ëœ ë‹µë³€: {generated_answer}")
    print("="*50)


if __name__ == "__main__":
    main()